import requests
from bs4 import BeautifulSoup
import json

# URL da l√¢mina que voc√™ mandou o print (Est√¥mago)
url = "https://histologyguide.com/slideview/MH-111a-cardioesophageal-junction/14-slide-2.html"

print(f"üïµÔ∏è Acessando: {url}...")

# Fingindo ser um navegador comum para n√£o ser bloqueado
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}

try:
    response = requests.get(url, headers=headers)
    soup = BeautifulSoup(response.content, 'html.parser')

    # 1. Pegar o T√≠tulo da L√¢mina
    titulo = soup.find('h2').text.strip() if soup.find('h2') else "T√≠tulo n√£o encontrado"
    
    # 2. Pegar a Descri√ß√£o (Texto lateral)
    # No HTML deles, a descri√ß√£o est√° dentro de uma div com id 'sidebar'
    sidebar = soup.find('div', id='sidebar')
    descricao = sidebar.find('p').text.strip() if sidebar and sidebar.find('p') else "Sem descri√ß√£o"

    # 3. Extrair os bot√µes/marca√ß√µes (As estruturas anat√¥micas)
    marcacoes = []
    # Eles usam bot√µes dentro de listas <ul> com 'onclick' para o zoom
    botoes = sidebar.find_all('button') if sidebar else []
    
    for botao in botoes:
        nome_estrutura = botao.text.strip()
        acao_zoom = botao.get('onclick') # Ex: zZoomAndPanToView(28273, 10367, 3.6)
        
        if acao_zoom and 'zZoomAndPanToView' in acao_zoom:
            # Limpando o texto para pegar s√≥ os n√∫meros
            numeros = acao_zoom.replace('zZoomAndPanToView(', '').replace(')', '').split(',')
            if len(numeros) >= 3:
                x = int(numeros[0].strip())
                y = int(numeros[1].strip())
                zoom = float(numeros[2].strip())
                
                marcacoes.append({
                    "nome": nome_estrutura,
                    "x_original": x,
                    "y_original": y,
                    "zoom": zoom
                })

    # Criando o objeto final
    lamina_data = {
        "titulo": titulo,
        "url_origem": url,
        "descricao": descricao,
        "estruturas_identificadas": marcacoes
    }

    # Salvando em um arquivo JSON
    with open('laminas_coletadas.json', 'w', encoding='utf-8') as f:
        json.dump(lamina_data, f, indent=4, ensure_ascii=False)

    print("‚úÖ Sucesso! Dados salvos em 'laminas_coletadas.json'")
    print(f"T√≠tulo: {titulo}")
    print(f"Estruturas encontradas: {len(marcacoes)}")

except Exception as e:
    print(f"‚ùå Erro ao acessar: {e}")
